{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your name:\n",
    "\n",
    "<pre> Isaac Aktam</pre>\n",
    "\n",
    "### Collaborators:\n",
    "\n",
    "<pre> Enter the name of the people you worked with if any</pre>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Markdown referece can be found here:\n",
    "    http://nestacms.com/docs/creating-content/markdown-cheat-sheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. Why would it be a problem if our training set and test set are the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre> The problem with the training set being the same as the test set is that we end up with the model that does not generazie well or does not generaize at all. The model might work well, or even great, on the test that is the same as  the training set, but it may utterly fail on the new test sets. The issue with this is that it may lead to overfitting</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2 [OPTIONAL]. Explain step by step the process to select k in the k-nearest neighbor algorithm (pseudocode) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre> \n",
    "k-nearest neighbour\n",
    "Classify (X, Y, x) // X: training data, Y: class labels, x: unknown sample\n",
    "for i = 1 to m do:\n",
    "   Compute distance d(X_i, x)\n",
    "end for\n",
    "Compute set I containing indices for the k smallest distances d(X_i, x).\n",
    "return majority label for {Y_i where i âˆˆ I}   \n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3. For the k-nearest regression. What happends when k = n. Where n is equal to the training size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre> We may end up looking at samples that are not the closest neighbours. It is like claiming that someone who is currently residing in Beijing is your neighbour while you reside in Toronto. </pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. Define a function that takes a 1-d numpy array, a parameter k, and a number p.\n",
    "The function returns an estimate equal to the mean of the closest k points to the number p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def k_neighbor(input_data, k, p):\n",
    "    \"\"\"Returns the k-neighbor estimate for p using data input_data.\n",
    "    \n",
    "    Keyword arguments:\n",
    "    input_data -- numpy array of all the data\n",
    "    k -- Number of k\n",
    "    p -- input values\n",
    "    \n",
    "    If you make assumptions please explain them in the comments. i.e. tie breaking strategy.\n",
    "    \"\"\"\n",
    "    \n",
    "    #YOUR CODE HERE\n",
    "    # Step 1, find the Eucledian distance between p and the values in the input_data\n",
    "    \n",
    "    distances = [np.linalg.norm(p - i) for i in input_data]\n",
    "    \n",
    "    # Step 2, combine input_data and distances into 2 x len(input_data) array\n",
    "    \n",
    "    master_array = np.array([input_data, distances])\n",
    "    \n",
    "    # Step 3, sort master_array with respect to the distances sub array\n",
    "    \n",
    "    # create a tuples of indexes and corresponding data values\n",
    "    list_of_tuples = list(enumerate(master_array[1])) \n",
    "    # sort the list of tuples with respect to indexes\n",
    "    sorted_list_of_tuples = sorted(list_of_tuples,key=lambda x:x[1]) \n",
    "    # retrieve indexes from the sorted result\n",
    "    indexes =[i[0] for i in sorted_list_of_tuples] \n",
    "    # sort the master_array with respect to distances; use indexes to sort the master_array\n",
    "    master_array = master_array[: , indexes] \n",
    "    \n",
    "    # Step 4, select the k-neighbours; please note that the p can be a neighbour with the element of \n",
    "    # itself in the input_data array\n",
    "    \n",
    "    neighbours = master_array[0][0:k]\n",
    "    mean_neighbours = np.mean(neighbours, axis = 0)\n",
    "    mean_neighbours = np.round(mean_neighbours, decimals = 4)\n",
    "    # neighbours = pd.DataFrame(neighbours, columns = [\"%d nearest neighbours\" %k])\n",
    "    \n",
    "    # Step 5, return answer\n",
    "    \n",
    "    return (\"mean 1d vector for k = %r neighbours and input value = %r is %r\" % (k, p, mean_neighbours))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean 1d vector for k = 3 neighbours and input value = 5 is 4.0\n",
      "mean 1d vector for k = 2 neighbours and input value = 15 is 14.0\n",
      "mean 1d vector for k = 3 neighbours and input value = 25 is 26.0\n",
      "mean 1d vector for k = 10 neighbours and input value = 25 is 19.6\n",
      "mean 1d vector for k = 1 neighbours and input value = 55 is 40.0\n",
      "mean 1d vector for k = 3 neighbours and input value = 55 is 31.3333\n",
      "mean 1d vector for k = 10 neighbours and input value = 55 is 19.6\n"
     ]
    }
   ],
   "source": [
    "#Evaluate\n",
    "data = np.array([1,3,4,5,7,8,11,12,13,15,19,24,25,29,40])\n",
    "print(k_neighbor(input_data=data, k=3, p=5))\n",
    "print(k_neighbor(input_data=data, k=2, p=15))\n",
    "print(k_neighbor(input_data=data, k=3, p=25))\n",
    "\n",
    "print(k_neighbor(input_data=data, k=10, p=25))\n",
    "\n",
    "print(k_neighbor(input_data=data, k=1, p=55))\n",
    "print(k_neighbor(input_data=data, k=3, p=55))\n",
    "print(k_neighbor(input_data=data, k=10, p=55))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For Q4, we can make the following conclusions.\n",
    "\n",
    "# Conclusion 1: For values of p that are within the input_data and with reasonably sized k, we get pretty reasonable \n",
    "# predictions with +/- 1 accuracy.\n",
    "\n",
    "# Conclusion 2: For values of p that are within the input data with large k (10), we get unsatisfactory results. \n",
    "# E.g., when k = 10, difference between p and the mean values is 5.4\n",
    "\n",
    "# Conclusion 3: For values of p (e.g., 50) that are not in the input_data, we get mean values unsatisfactory \n",
    "#results since. For example, when k = 1, difference between p and the mean value is 15; when k = 3, \n",
    "# difference is 23.66666; when k = 10, difference is 35.4.\n",
    "\n",
    "# Therefore, to get reasonable, if not accurate, results we need to have input values p to be within the input_data \n",
    "# and k values to be reasonably low.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5. Similar to Q4 but for the n dimentional case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def l1_norm(a,b):\n",
    "    \"\"\"Returns the l1 norm (a,b)\"\"\"\n",
    "    l1_norm = numpy.linalg.norm((a - b), ord = 1)\n",
    "    return l1_norm\n",
    "    \n",
    "def l2_norm(a,b):\n",
    "    \"\"\"Returns the l2 norm (a,b)\"\"\" \n",
    "    l2_norm = numpy.linalg.norm((a - b), ord = 2)\n",
    "    \n",
    "def k_neighbor_nd(input_data, k, p, metric='l1', mode='mean'):\n",
    "    \"\"\"Returns the k-neighbor estimate for p using data input_data.\n",
    "\n",
    "    Keyword arguments:\n",
    "    input_data -- numpy array of all the data\n",
    "    k -- Number of k\n",
    "    p -- input values\n",
    "    metric -- l1 or l2. l1 norm or l2 norm https://en.wikipedia.org/wiki/Norm_(mathematics)\n",
    "    mode -- estimator possible values = 'mean', 'median', 'max'\n",
    "    \n",
    "    Implement the l1 and l2 norms\n",
    "    for mean, median and max, use np.mean, np.median and np.max\n",
    "    \"\"\"\n",
    "    \n",
    "    #YOUR CODE HERE\n",
    "    \n",
    "    # Step 1, find the Eucledian distance between p and the values in the input_data\n",
    "    \n",
    "    if metric == 'l1':\n",
    "        distances = [np.linalg.norm((p - i), ord = 1) for i in input_data]\n",
    "    elif metric == 'l2':\n",
    "        distances = [np.linalg.norm((p - i), ord = 2) for i in input_data]\n",
    "    else:\n",
    "        print(\"The norm you specified is outside the given parameters. Please choose between either l1 or l2\")\n",
    "    \n",
    "    # print(distances)\n",
    "    \n",
    "    # Step 2, combine input_data and distances into 2 x len(input_data) array\n",
    "    \n",
    "    # Generate keys for the dictionary using the input_data.shape[0]\n",
    "    \n",
    "    keys = [i for i in range(input_data.shape[0])]\n",
    "    \n",
    "    # Create a dictionary with keys between o and 13 and values being the arrays in input_data\n",
    "    \n",
    "    dict_of_arr = dict(zip(keys, input_data))\n",
    "    \n",
    "    # Step 3, combine keys and distances into an array\n",
    "    # After ordering the master_arr w.r.t. distances, retrieve k keys and thusly retrive the k arrays in input_data\n",
    "    \n",
    "    master_arr = np.array([keys, distances])\n",
    "    \n",
    "    # print(master_arr)\n",
    "    \n",
    "    # Step 4, reoder the master_arr w.r.t. distances array\n",
    "    \n",
    "    list_of_tuples = list(enumerate(master_arr[1]))\n",
    "    sorted_list_of_tuples = sorted(list_of_tuples,key=lambda x:x[1])\n",
    "    indexes =[i[0] for i in sorted_list_of_tuples]\n",
    "    master_arr = master_arr[: , indexes]\n",
    "    # print(master_arr)\n",
    "    \n",
    "    # Step 4.1. get sorted distances from the sorted master_arr\n",
    "    \n",
    "    dist_sort = master_arr[1][0:k]\n",
    "    # print(master_arr[1])\n",
    "    # print(dist_sort)\n",
    "    \n",
    "    # Step 5, retrieve keys for the least distances from the master_arr\n",
    "    \n",
    "    neighbour_keys = master_arr[0][0:k]\n",
    "    #neighbour_keys = master_arr[0]\n",
    "    #print(neighbour_keys)\n",
    "    \n",
    "    # Step 6, use keys to retrieve the neighbours\n",
    "    \n",
    "    neighbours = [dict_of_arr[r] for r in neighbour_keys]\n",
    "    neighbours = np.array(neighbours) # Do not delete\n",
    "    # neighbours = pd.DataFrame({'%d nearest neighbours' %(k):neighbours}) # Do not delete this\n",
    "    # print(neighbours) # Do not delete\n",
    "    \n",
    "    # Step 7, determine either mean, median, or max of the k neighbor vectors\n",
    "    \n",
    "    if mode == 'mean': # Mean case, find row mean of the k neighbor array\n",
    "        mode_array = np.mean(neighbours, axis = 0)\n",
    "        mode_array = np.round(mode_array, decimals = 4)\n",
    "    elif mode == 'median':\n",
    "        mode_array = np.median(neighbours, axis = 0)\n",
    "        mode_array = np.round(mode_array, decimals = 4)\n",
    "    elif mode == 'max':\n",
    "        mode_array = np.max(neighbours, axis = 0)\n",
    "        mode_array = np.round(mode_array, decimals = 4)\n",
    "    else:\n",
    "        print('Sorry mate, no other mode exists. Please select either mean, median, or mode')\n",
    "    \n",
    "    return (\"%r vector for k = %r neighbours, norm =  %r, and input value = %r is %r \" \n",
    "            % (mode, k, metric, p, mode_array))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_4d = np.array([[4, 1, 2, 1], [1, 4, 2, 0], [3, 3, 1, 1], \n",
    "        [4, 0, 0, 0], [1, 2, 0, 0], [3, 4, 2, 3], \n",
    "        [2, 4, 4, 2], [2, 1, 4, 1], [3, 3, 2, 4], \n",
    "        [4, 3, 0, 4], [2, 2, 4, 0],[4, 3, 0, 2], \n",
    "        [4, 3, 0, 2], [0, 3, 4, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'mean' vector for k = 3 neighbours, norm =  'l1', and input value = [2, 1, 4, 3] is array([2.    , 2.3333, 4.    , 1.    ]) \n",
      "'mean' vector for k = 2 neighbours, norm =  'l1', and input value = [4, 4, 0, 0] is array([4., 3., 0., 2.]) \n",
      "'max' vector for k = 3 neighbours, norm =  'l1', and input value = [2, 2, 2, 4] is array([4, 4, 2, 4]) \n",
      "'mean' vector for k = 1 neighbours, norm =  'l1', and input value = [2, 3, 3, 4] is array([3., 3., 2., 4.]) \n",
      "'median' vector for k = 3 neighbours, norm =  'l1', and input value = [2, 3, 3, 4] is array([3., 4., 2., 3.]) \n",
      "'mean' vector for k = 3 neighbours, norm =  'l2', and input value = [2, 1, 4, 3] is array([1.3333, 2.6667, 4.    , 1.6667]) \n",
      "'mean' vector for k = 2 neighbours, norm =  'l2', and input value = [4, 4, 0, 0] is array([3.5, 3. , 0.5, 1.5]) \n",
      "'max' vector for k = 3 neighbours, norm =  'l2', and input value = [2, 2, 2, 4] is array([4, 4, 2, 4]) \n",
      "'mean' vector for k = 1 neighbours, norm =  'l2', and input value = [2, 3, 3, 4] is array([3., 3., 2., 4.]) \n",
      "'median' vector for k = 3 neighbours, norm =  'l2', and input value = [2, 3, 3, 4] is array([3., 4., 2., 3.]) \n"
     ]
    }
   ],
   "source": [
    "#Evaluate\n",
    "data = np.array([1,3,4,5,7,8,11,12,13,15,19,24,25,29,40])\n",
    "print(k_neighbor_nd(input_data=data_4d, k=3, p=[2, 1, 4, 3], metric='l1', mode='mean'))\n",
    "print(k_neighbor_nd(input_data=data_4d, k=2, p=[4, 4, 0, 0], metric='l1', mode='mean'))\n",
    "print(k_neighbor_nd(input_data=data_4d, k=3, p=[2, 2, 2, 4], metric='l1', mode='max'))\n",
    "print(k_neighbor_nd(input_data=data_4d, k=1, p=[2, 3, 3, 4], metric='l1', mode='mean'))\n",
    "print(k_neighbor_nd(input_data=data_4d, k=3, p=[2, 3, 3, 4], metric='l1', mode='median'))\n",
    "print(k_neighbor_nd(input_data=data_4d, k=3, p=[2, 1, 4, 3], metric='l2', mode='mean'))\n",
    "print(k_neighbor_nd(input_data=data_4d, k=2, p=[4, 4, 0, 0], metric='l2', mode='mean'))\n",
    "print(k_neighbor_nd(input_data=data_4d, k=3, p=[2, 2, 2, 4], metric='l2', mode='max'))\n",
    "print(k_neighbor_nd(input_data=data_4d, k=1, p=[2, 3, 3, 4], metric='l2', mode='mean'))\n",
    "print(k_neighbor_nd(input_data=data_4d, k=3, p=[2, 3, 3, 4], metric='l2', mode='median'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6[Optional]. Read the documentation on KNeighborsRegressor\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html\n",
    "    \n",
    "Explore the source code:\n",
    "    https://github.com/scikit-learn/scikit-learn/blob/ef5cb84a/sklearn/neighbors/regression.py\n",
    "        \n",
    "How different it is from your implementation? How well can you follow the code? Did you learn something new?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "Q1. How well can I follow the code? - Given enough time and dedication, the code starts to make sense. Additionally, the examples provided in documentation made code easier to understand. With practice, it will make easier to understand the code and its full implementation. For now, I would say it was rather challenging to follow the code. I will need to consinstenly improve my skills in order to further understand how various algorithms work and how to implement them properly. \n",
    "Q2. How different is it from my implementation? - The first thing I notice is that, in the documentation, there are such variables as weights, algorithm, leaf size, p, metric, metric_params, n_jobs. In our assignment, we don't have such variables. In our assignment we simply have neighbour vectors, size of k, and the vector p in question for which need to calculate k neighbors with the shortest k distances. We don't have so called training set or test set. Additionally, in our assignment we don't have many of the variables that are in KNeghborsRegressor. \n",
    "Q3. Did I learn something new? - Yes, that there is already a whole library built for knn classification. I learned about different types of weights (uniform, distance, callable), that the default amount of weights in KNeighborsRegressor is 5 (I wonder what the logic behind the 5 is), different types algorithms (ball_tree, kd_tree, brute, auto) within the KNeighborsRegressor, that there also exists a leaf_size that is crucial for the performance of the ball_tree and kd_tree algorithms in terms of their speed and output, that different values of result in different values of distance (I did not know that there existed Minkowski distance), and that the depending from the n_jobs a different number of CPUs can be used. Fascinating! Next thing I learned that if neighbours k+1 and k have identical distances but different labels, the results will depend on the ordering of the training data (good to know for future work). As I continue to practice further, I will keep learning more. Also, what i learned is the whole assignment code(solution?) can be pretty much condensed into few lines of code with the most important one being \"from sklearn.neighbors import NearestNeighbors\". Fantastic, isn't it?\n",
    "\n",
    "Q4 can be solved as the following:\n",
    ">>> samples = np.array([1,3,4,5,7,8,11,12,13,15,19,24,25,29,40])\n",
    ">>> samples = samples.reshape(-1, 1)\n",
    ">>> from sklearn.neighbors import NearestNeighbors\n",
    ">>> neigh = NearestNeighbors(n_neighbors=3)\n",
    ">>> neigh.fit(samples) \n",
    "NearestNeighbors(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "         metric_params=None, n_jobs=1, n_neighbors=3, p=2, radius=1.0)\n",
    ">>> print(neigh.kneighbors([[5.]]))\n",
    "(array([[0., 1., 2.]]), array([[3, 2, 1]]))\n",
    "\n",
    "So, the three (5, 4, 3) elements at the indexes 3, 2, 1 are 0, 1, 2 distances away from 5. Nice!\n",
    "\n",
    "I guess, to solve all the other cases we would need to write \"neigh = NearestNeighbors(n_neighbors = k)\" and \"print(neigh.kneighbors([[p]]))\"\n",
    "\n",
    "What would be cool to have is a set of small exercises pertaining to each of the topics that we are covering in class and then have an assignment at the of the week. For example, exercises could include problems related to each of the methods belonging to the algorithm, in this case we have KNeigborsRegressor.\n",
    "\n",
    "\n",
    "</pre>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
