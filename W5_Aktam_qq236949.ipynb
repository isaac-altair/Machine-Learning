{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your name:\n",
    "\n",
    "<pre> Isaac Aktam</pre>\n",
    "\n",
    "### Collaborators:\n",
    "\n",
    "<pre> Ashish Gupta, Konrad Korzeniewski</pre>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment for Module 5, Training Models\n",
    "\n",
    "In this assignment you will train different models on a given data set, and find the one that performs best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the data for the assignment (similar to the notebook from chapter 2 of Hands-On...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "from six.moves import urllib\n",
    "\n",
    "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml/master/\"\n",
    "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
    "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
    "\n",
    "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
    "    if not os.path.isdir(housing_path):\n",
    "        os.makedirs(housing_path)\n",
    "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
    "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
    "    housing_tgz = tarfile.open(tgz_path)\n",
    "    housing_tgz.extractall(path=housing_path)\n",
    "    housing_tgz.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fetch_housing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_housing_data(housing_path=HOUSING_PATH):\n",
    "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
    "    return pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "housing = load_housing_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix the categories in the categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = {'<1H OCEAN':'LESS_1H_OCEAN', 'INLAND':'INLAND', 'ISLAND':'ISLAND', 'NEAR BAY':'NEAR_BAY', 'NEAR OCEAN':'NEAR_OCEAN'}\n",
    "housing['ocean_proximity'] = housing['ocean_proximity'].map(lambda s: d[s])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add 2 more features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "housing[\"rooms_per_household\"] = housing[\"total_rooms\"]/housing[\"households\"]\n",
    "housing[\"population_per_household\"]=housing[\"population\"]/housing[\"households\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "median = housing[\"total_bedrooms\"].median()\n",
    "housing[\"total_bedrooms\"].fillna(median, inplace=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dummy variables based on the categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "one_hot = pd.get_dummies(housing['ocean_proximity'])\n",
    "housing = housing.drop('ocean_proximity', axis=1)\n",
    "housing = housing.join(one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 16 columns):\n",
      "longitude                   20640 non-null float64\n",
      "latitude                    20640 non-null float64\n",
      "housing_median_age          20640 non-null float64\n",
      "total_rooms                 20640 non-null float64\n",
      "total_bedrooms              20640 non-null float64\n",
      "population                  20640 non-null float64\n",
      "households                  20640 non-null float64\n",
      "median_income               20640 non-null float64\n",
      "median_house_value          20640 non-null float64\n",
      "rooms_per_household         20640 non-null float64\n",
      "population_per_household    20640 non-null float64\n",
      "INLAND                      20640 non-null uint8\n",
      "ISLAND                      20640 non-null uint8\n",
      "LESS_1H_OCEAN               20640 non-null uint8\n",
      "NEAR_BAY                    20640 non-null uint8\n",
      "NEAR_OCEAN                  20640 non-null uint8\n",
      "dtypes: float64(11), uint8(5)\n",
      "memory usage: 1.8 MB\n"
     ]
    }
   ],
   "source": [
    "housing.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASSIGNMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Partition into train and test\n",
    "\n",
    "Use train_test_split from sklearn.model_selection to partition the dataset into 70% for training and 30% for testing.\n",
    "\n",
    "You can use the 70% for training set as both training and validation by using cross-validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(housing, test_size = 0.3, random_state = 42)## YOUR CODE HERE ## REMEMBER TO INCLUDE THE RANDOM STATE = 42\n",
    "\n",
    "# Do we use the stratified sampling?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = 'median_house_value'\n",
    "features = list(train_set.columns)\n",
    "features = [f for f in features if f!=target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['longitude',\n",
       " 'latitude',\n",
       " 'housing_median_age',\n",
       " 'total_rooms',\n",
       " 'total_bedrooms',\n",
       " 'population',\n",
       " 'households',\n",
       " 'median_income',\n",
       " 'rooms_per_household',\n",
       " 'population_per_household',\n",
       " 'INLAND',\n",
       " 'ISLAND',\n",
       " 'LESS_1H_OCEAN',\n",
       " 'NEAR_BAY',\n",
       " 'NEAR_OCEAN']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_tr = train_set[features]\n",
    "y_tr = train_set[[target]]\n",
    "\n",
    "X_te = test_set[features]\n",
    "y_te = test_set[[target]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Polynomial transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use PolynomialFeatures from sklearn.preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(2)\n",
    "poly.fit(X_tr)\n",
    "X_tr = poly.fit_transform(X_tr)## YOUR CODE HERE ##\n",
    "X_te = poly.transform(X_te)## YOUR CODE HERE ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " 'longitude',\n",
       " 'latitude',\n",
       " 'housing_median_age',\n",
       " 'total_rooms',\n",
       " 'total_bedrooms',\n",
       " 'population',\n",
       " 'households',\n",
       " 'median_income',\n",
       " 'rooms_per_household',\n",
       " 'population_per_household',\n",
       " 'INLAND',\n",
       " 'ISLAND',\n",
       " 'LESS_1H_OCEAN',\n",
       " 'NEAR_BAY',\n",
       " 'NEAR_OCEAN',\n",
       " 'longitude^2',\n",
       " 'longitude latitude',\n",
       " 'longitude housing_median_age',\n",
       " 'longitude total_rooms',\n",
       " 'longitude total_bedrooms',\n",
       " 'longitude population',\n",
       " 'longitude households',\n",
       " 'longitude median_income',\n",
       " 'longitude rooms_per_household',\n",
       " 'longitude population_per_household',\n",
       " 'longitude INLAND',\n",
       " 'longitude ISLAND',\n",
       " 'longitude LESS_1H_OCEAN',\n",
       " 'longitude NEAR_BAY',\n",
       " 'longitude NEAR_OCEAN',\n",
       " 'latitude^2',\n",
       " 'latitude housing_median_age',\n",
       " 'latitude total_rooms',\n",
       " 'latitude total_bedrooms',\n",
       " 'latitude population',\n",
       " 'latitude households',\n",
       " 'latitude median_income',\n",
       " 'latitude rooms_per_household',\n",
       " 'latitude population_per_household',\n",
       " 'latitude INLAND',\n",
       " 'latitude ISLAND',\n",
       " 'latitude LESS_1H_OCEAN',\n",
       " 'latitude NEAR_BAY',\n",
       " 'latitude NEAR_OCEAN',\n",
       " 'housing_median_age^2',\n",
       " 'housing_median_age total_rooms',\n",
       " 'housing_median_age total_bedrooms',\n",
       " 'housing_median_age population',\n",
       " 'housing_median_age households',\n",
       " 'housing_median_age median_income',\n",
       " 'housing_median_age rooms_per_household',\n",
       " 'housing_median_age population_per_household',\n",
       " 'housing_median_age INLAND',\n",
       " 'housing_median_age ISLAND',\n",
       " 'housing_median_age LESS_1H_OCEAN',\n",
       " 'housing_median_age NEAR_BAY',\n",
       " 'housing_median_age NEAR_OCEAN',\n",
       " 'total_rooms^2',\n",
       " 'total_rooms total_bedrooms',\n",
       " 'total_rooms population',\n",
       " 'total_rooms households',\n",
       " 'total_rooms median_income',\n",
       " 'total_rooms rooms_per_household',\n",
       " 'total_rooms population_per_household',\n",
       " 'total_rooms INLAND',\n",
       " 'total_rooms ISLAND',\n",
       " 'total_rooms LESS_1H_OCEAN',\n",
       " 'total_rooms NEAR_BAY',\n",
       " 'total_rooms NEAR_OCEAN',\n",
       " 'total_bedrooms^2',\n",
       " 'total_bedrooms population',\n",
       " 'total_bedrooms households',\n",
       " 'total_bedrooms median_income',\n",
       " 'total_bedrooms rooms_per_household',\n",
       " 'total_bedrooms population_per_household',\n",
       " 'total_bedrooms INLAND',\n",
       " 'total_bedrooms ISLAND',\n",
       " 'total_bedrooms LESS_1H_OCEAN',\n",
       " 'total_bedrooms NEAR_BAY',\n",
       " 'total_bedrooms NEAR_OCEAN',\n",
       " 'population^2',\n",
       " 'population households',\n",
       " 'population median_income',\n",
       " 'population rooms_per_household',\n",
       " 'population population_per_household',\n",
       " 'population INLAND',\n",
       " 'population ISLAND',\n",
       " 'population LESS_1H_OCEAN',\n",
       " 'population NEAR_BAY',\n",
       " 'population NEAR_OCEAN',\n",
       " 'households^2',\n",
       " 'households median_income',\n",
       " 'households rooms_per_household',\n",
       " 'households population_per_household',\n",
       " 'households INLAND',\n",
       " 'households ISLAND',\n",
       " 'households LESS_1H_OCEAN',\n",
       " 'households NEAR_BAY',\n",
       " 'households NEAR_OCEAN',\n",
       " 'median_income^2',\n",
       " 'median_income rooms_per_household',\n",
       " 'median_income population_per_household',\n",
       " 'median_income INLAND',\n",
       " 'median_income ISLAND',\n",
       " 'median_income LESS_1H_OCEAN',\n",
       " 'median_income NEAR_BAY',\n",
       " 'median_income NEAR_OCEAN',\n",
       " 'rooms_per_household^2',\n",
       " 'rooms_per_household population_per_household',\n",
       " 'rooms_per_household INLAND',\n",
       " 'rooms_per_household ISLAND',\n",
       " 'rooms_per_household LESS_1H_OCEAN',\n",
       " 'rooms_per_household NEAR_BAY',\n",
       " 'rooms_per_household NEAR_OCEAN',\n",
       " 'population_per_household^2',\n",
       " 'population_per_household INLAND',\n",
       " 'population_per_household ISLAND',\n",
       " 'population_per_household LESS_1H_OCEAN',\n",
       " 'population_per_household NEAR_BAY',\n",
       " 'population_per_household NEAR_OCEAN',\n",
       " 'INLAND^2',\n",
       " 'INLAND ISLAND',\n",
       " 'INLAND LESS_1H_OCEAN',\n",
       " 'INLAND NEAR_BAY',\n",
       " 'INLAND NEAR_OCEAN',\n",
       " 'ISLAND^2',\n",
       " 'ISLAND LESS_1H_OCEAN',\n",
       " 'ISLAND NEAR_BAY',\n",
       " 'ISLAND NEAR_OCEAN',\n",
       " 'LESS_1H_OCEAN^2',\n",
       " 'LESS_1H_OCEAN NEAR_BAY',\n",
       " 'LESS_1H_OCEAN NEAR_OCEAN',\n",
       " 'NEAR_BAY^2',\n",
       " 'NEAR_BAY NEAR_OCEAN',\n",
       " 'NEAR_OCEAN^2']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's get the names of all the 136 features as we would need to isolate the categorical featues for further analysis\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "array_of_features = np.array(features)\n",
    "feature_names_transformed = poly.get_feature_names(array_of_features)\n",
    "feature_names_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(136,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(feature_names_transformed).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's get the location of each of the squared categorical variable\n",
    "\n",
    "list_of_cat_vars = ['INLAND', 'ISLAND', 'LESS_1H_OCEAN', 'NEAR_BAY', 'NEAR_OCEAN', \n",
    "                    'INLAND ISLAND', 'INLAND LESS_1H_OCEAN', 'INLAND NEAR_BAY', 'INLAND NEAR_OCEAN',\n",
    "                    'ISLAND LESS_1H_OCEAN', 'ISLAND NEAR_BAY', 'ISLAND NEAR_OCEAN',\n",
    "                    'LESS_1H_OCEAN NEAR_BAY', 'LESS_1H_OCEAN NEAR_OCEAN',\n",
    "                    'NEAR_BAY NEAR_OCEAN',\n",
    "                    'INLAND^2', 'ISLAND^2', 'LESS_1H_OCEAN^2', 'NEAR_BAY^2', 'NEAR_OCEAN^2']\n",
    "\n",
    "indexes_of_cat_vars = [feature_names_transformed.index(item) for item in list_of_cat_vars]\n",
    "# [11, 12, 13, 14, 15, 122, 123, 124, 125, 127, 128, 129, 131, 132, 134, 121, 126, 130, 133, 135]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### You should obtain X_tr and X_te with 136 columns each, since originally you had 15 features.\n",
    "\n",
    "##### With m original features, the new added polynomial features of degree 2 are: $(m^2-m)/2+m+1$. Why?\n",
    "\n",
    "##### These, plus the original features gives a total of  $(m^2-m)/2+2m+1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PolynomialFeatures(degree=d) transforms an array containing n features into an array containing $(n+d)!/(d!n!)$ features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of features: 15\n",
      "Final number of features: 136\n"
     ]
    }
   ],
   "source": [
    "print(\"Original number of features: \"+str(len(features)))\n",
    "print(\"Final number of features: \"+str(X_tr.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Scaling features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, use StandardScaler from sklearn.preprocessing to normalize the training and testing data, using the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Hold on to this for now, I want to try something else\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# There is nothing in Scikit-Learn to handle Pandas DataFrames, so we need to write a custom transformer for this\n",
    "# task\n",
    "\n",
    "# DataFrameSelector is correct\n",
    "\n",
    "indexes_of_X_tr = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, \n",
    "                     26, 27, 28, 29, 30,  31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, \n",
    "                     49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, \n",
    "                     72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86,  87, 88, 89, 90, 91, 92, 93, \n",
    "                     94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, \n",
    "                     112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 127, 128, 129, \n",
    "                     131, 132, 134, 135]\n",
    "\n",
    "cat_attribs = [11, 12, 13, 14, 15, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135]\n",
    "#cat_attribs = list(map(str, list_of_cat_indexes)) # integers are transformend into strings; to be used in dataframe\n",
    "\n",
    "# Transform X_tr and X_te into pandas dataframe\n",
    "\n",
    "X_tr = pd.DataFrame(X_tr)\n",
    "X_te = pd.DataFrame(X_te)\n",
    "\n",
    "# Create the pipelines\n",
    "\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names].values    \n",
    "    \n",
    "num_data = X_tr.drop(cat_attribs, axis = 1)\n",
    "\n",
    "num_attribs = list(num_data)\n",
    "\n",
    "num_pipeline = Pipeline([('selector', DataFrameSelector(num_attribs)),\n",
    "                         ('std_scaler', StandardScaler())])\n",
    "\n",
    "\n",
    "cat_pipeline = Pipeline([('selector', DataFrameSelector(cat_attribs))])\n",
    "\n",
    "full_pipeline = FeatureUnion([(\"num_pipeline\", num_pipeline), \n",
    "                              (\"cat_pipeline\", cat_pipeline)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_trans = full_pipeline.fit_transform(X_tr) # Transform the X_tr values\n",
    "\n",
    "X_test_trans = full_pipeline.transform(X_te) # Transform the X_te values\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "num_pipeline = Pipeline([('std_scaler', StandardScaler())])\n",
    "\n",
    "y_train_trans = num_pipeline.fit_transform(y_tr) # Transform the y_tr values\n",
    "y_test_trans = num_pipeline.transform(y_te) # Transform the y_te values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Linear regression on original features (no transformations) --- benchmark\n",
    "\n",
    "#### Your goal is to find the model that minimizes the rmse score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [70142.55721218 67456.39127204 67318.3258893  70866.26065275]\n",
      "Mean: 68945.88375656825\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lin_scores = cross_val_score(LinearRegression(), train_set[features], train_set[target], scoring=\"neg_mean_squared_error\", cv=4)\n",
    "lin_rmse_scores = np.sqrt(-lin_scores)\n",
    "display_scores(lin_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Linear regression  (on transformed features: polynomial transformation + scaling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do as in 4 but with the original and transformed features (136 features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [3.55940432e+09 9.16652461e+09 1.14155948e+09 1.86803676e+11]\n",
      "Mean: 50167791197.25261\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression ## YOUR CODE HERE ##\n",
    "lin_scores = cross_val_score(LinearRegression(), X_train_trans, y_train_trans, scoring=\"neg_mean_squared_error\", cv=4) ## YOUR CODE HERE ##\n",
    "lin_rmse_scores = np.sqrt(-lin_scores) ## YOUR CODE HERE ##\n",
    "display_scores(lin_rmse_scores) ## YOUR CODE HERE ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the error on the cross-validation is too high it is because the model is over-fitting. Regularization is needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'alpha': [0.001, 0.01, 0.1, 1, 10, 100, 1000, 1000]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "param_grid = [{'alpha': [0.001,0.01,0.1,1,10,100,1000,1000]}]\n",
    "grid_search_rr = GridSearchCV(Ridge(), param_grid, cv=3, scoring='neg_mean_squared_error')\n",
    "grid_search_rr.fit(X_train_trans, y_train_trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearchCV(cv=3, error_score='raise',\n",
    "       estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
    "   normalize=False, random_state=None, solver='auto', tol=0.001),\n",
    "       fit_params=None, iid=True, n_jobs=1,\n",
    "       param_grid=[{'alpha': [0.001, 0.01, 0.1, 1, 10, 100, 1000, 1000]}],\n",
    "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
    "       scoring='neg_mean_squared_error', verbose=0)\n",
    "\n",
    "{'alpha': 1000}\n",
    "0.580781678141058"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1000}\n",
      "0.580781678141058\n"
     ]
    }
   ],
   "source": [
    "print(grid_search_rr.best_params_)\n",
    "print(np.sqrt(-grid_search_rr.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Lasso regression\n",
    "\n",
    "Now do the same as in 6 but with Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/isaac/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/isaac/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/isaac/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'alpha': [0.001, 0.01, 0.1, 1, 10, 100, 1000, 1000]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso ## YOUR CODE HERE ##\n",
    "param_grid = [{'alpha': [0.001,0.01,0.1,1,10,100,1000,1000]}] ## YOUR CODE HERE ##\n",
    "grid_search_lasso = GridSearchCV(Lasso(), param_grid, cv=3, scoring='neg_mean_squared_error') ## YOUR CODE HERE ##\n",
    "grid_search_lasso.fit(X_train_trans, y_train_trans)## YOUR CODE HERE ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearchCV(cv=3, error_score='raise',\n",
    "       estimator=Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
    "   normalize=False, positive=False, precompute=False, random_state=None,\n",
    "   selection='cyclic', tol=0.0001, warm_start=False),\n",
    "       fit_params=None, iid=True, n_jobs=1,\n",
    "       param_grid=[{'alpha': [0.001, 0.01, 0.1, 1, 10, 100, 1000, 1000]}],\n",
    "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
    "       scoring='neg_mean_squared_error', verbose=0)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.01}\n",
      "0.5786197997217288\n"
     ]
    }
   ],
   "source": [
    "print(grid_search_lasso.best_params_) ## YOUR CODE HERE ##\n",
    "print(np.sqrt(-grid_search_lasso.best_score_)) ## YOUR CODE HERE ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'alpha': 0.01}\n",
    "\n",
    "0.5786197997217292"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Elastic Net regression\n",
    "\n",
    "Do the same as in 6 and 7, but now with Elastic Net. However, the grid search should be over the parameters alpha and  l 1ratio. Use just 3 values for l1_ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/isaac/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/isaac/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/isaac/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/isaac/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/isaac/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/isaac/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/isaac/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/isaac/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/isaac/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/isaac/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/isaac/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/isaac/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/isaac/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/isaac/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/isaac/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/isaac/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/isaac/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/isaac/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/isaac/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/isaac/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/isaac/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/isaac/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/isaac/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/isaac/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/isaac/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/isaac/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/isaac/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/isaac/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/isaac/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/isaac/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
       "      max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "      random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'alpha': [0.001, 0.01, 0.1, 1, 10, 100, 1000, 1000], 'l1_ratio': [0, 0.5, 1]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet## YOUR CODE HERE ##\n",
    "\n",
    "param_grid = [{'alpha': [0.001,0.01,0.1,1,10,100,1000,1000], 'l1_ratio' : [0, 0.5, 1]}] ## YOUR CODE HERE ##\n",
    "grid_search_elastic_net = GridSearchCV(ElasticNet(), param_grid, cv=3, scoring='neg_mean_squared_error') ## YOUR CODE HERE ##\n",
    "grid_search_elastic_net.fit(X_train_trans, y_train_trans)## YOUR CODE HERE \n",
    "## YOUR CODE HERE ##\n",
    "## YOUR CODE HERE ##\n",
    "## YOUR CODE HERE ##\n",
    "## YOUR CODE HERE ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearchCV(cv=3, error_score='raise',\n",
    "       estimator=ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
    "      max_iter=1000, normalize=False, positive=False, precompute=False,\n",
    "      random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
    "       fit_params=None, iid=True, n_jobs=1,\n",
    "       param_grid=[{'alpha': [0.001, 0.01, 0.1, 1, 10, 100, 1000, 1000], 'l1_ratio': [0, 0.5, 1]}],\n",
    "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
    "       scoring='neg_mean_squared_error', verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.01, 'l1_ratio': 0.5}\n",
      "0.5693658353673012\n"
     ]
    }
   ],
   "source": [
    "print(grid_search_elastic_net.best_params_) ## YOUR CODE HERE ##\n",
    "print(np.sqrt(-grid_search_elastic_net.best_score_)) ## YOUR CODE HERE ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'alpha': 0.01, 'l1_ratio': 0.5}\n",
    "\n",
    "0.569365835367301"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating your best model on TESTING data\n",
    "\n",
    "Choose among grid_search_rr, grid_search_lr, and grid_search_enr, the model with best performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5714043869205295\n"
     ]
    }
   ],
   "source": [
    "# We choose the Elastic Net as our best model since it has the lowest MSRE\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "final_model = grid_search_elastic_net.best_estimator_   ## grid_search SHOULD BE THE BEST GRID SEARCH ##\n",
    "\n",
    "# Use standardized y_te_estimation\n",
    "# y_te_estimation = final_model.predict(X_te) # ORIGINAL, DON'T DELETE\n",
    "\n",
    "y_te_estimation = final_model.predict(X_test_trans)\n",
    "\n",
    "\n",
    "# Standardize y_te_estimation # REMOVE THE num_pipeline\n",
    "\n",
    "# y_test_estimation_trans = num_pipeline.fit_transform(y_te_estimation.reshape(-1, 1)) # Should we use fit_transform or transform\n",
    "\n",
    "\n",
    "# Use standardized y_test\n",
    "# final_mse = mean_squared_error(y_te, y_te_estimation) # ORIGINAL, DON'T DELETE\n",
    "\n",
    "final_mse = mean_squared_error(y_test_trans, y_te_estimation)\n",
    "final_rmse = np.sqrt(final_mse)\n",
    "print(final_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f79cfb624a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.scatter(x=y_te, y=y_te_estimation) # Original, DON'T DELETE\n",
    "\n",
    "# Used standardized values\n",
    "plt.scatter(x=y_test_trans, y=y_te_estimation)\n",
    "#plt.xlim([-200000,800000])\n",
    "#plt.ylim([-1.78785,-1.78765])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.532087262881342"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(y_test_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "101\n",
      "201\n",
      "301\n",
      "401\n",
      "501\n",
      "601\n",
      "701\n",
      "801\n",
      "901\n",
      "1001\n",
      "1101\n",
      "1201\n",
      "1301\n",
      "1401\n",
      "1501\n",
      "1601\n",
      "1701\n",
      "1801\n",
      "1901\n",
      "2001\n",
      "2101\n",
      "2201\n",
      "2301\n",
      "2401\n",
      "2501\n",
      "2601\n",
      "2701\n",
      "2801\n",
      "2901\n",
      "3001\n",
      "3101\n",
      "3201\n",
      "3301\n",
      "3401\n",
      "3501\n",
      "3601\n",
      "3701\n",
      "3801\n",
      "3901\n",
      "4001\n",
      "4101\n",
      "4201\n",
      "4301\n",
      "4401\n",
      "4501\n",
      "4601\n",
      "4701\n",
      "4801\n",
      "4901\n",
      "5001\n",
      "5101\n",
      "5201\n",
      "5301\n",
      "5401\n",
      "5501\n",
      "5601\n",
      "5701\n",
      "5801\n",
      "5901\n",
      "6001\n",
      "6101\n",
      "6201\n",
      "6301\n",
      "6401\n",
      "6501\n",
      "6601\n",
      "6701\n",
      "6801\n",
      "6901\n",
      "7001\n",
      "7101\n",
      "7201\n",
      "7301\n",
      "7401\n",
      "7501\n",
      "7601\n",
      "7701\n",
      "7801\n",
      "7901\n",
      "8001\n",
      "8101\n",
      "8201\n",
      "8301\n",
      "8401\n",
      "8501\n",
      "8601\n",
      "8701\n",
      "8801\n",
      "8901\n",
      "9001\n",
      "9101\n",
      "9201\n",
      "9301\n",
      "9401\n",
      "9501\n",
      "9601\n",
      "9701\n",
      "9801\n",
      "9901\n",
      "10001\n",
      "10101\n",
      "10201\n",
      "10301\n",
      "10401\n",
      "10501\n",
      "10601\n",
      "10701\n",
      "10801\n",
      "10901\n",
      "11001\n",
      "11101\n",
      "11201\n",
      "11301\n",
      "11401\n",
      "11501\n",
      "11601\n",
      "11701\n",
      "11801\n",
      "11901\n",
      "12001\n",
      "12101\n",
      "12201\n",
      "12301\n",
      "12401\n",
      "12501\n",
      "12601\n",
      "12701\n",
      "12801\n",
      "12901\n",
      "13001\n",
      "13101\n",
      "13201\n",
      "13301\n",
      "13401\n",
      "13501\n",
      "13601\n",
      "13701\n",
      "13801\n",
      "13901\n",
      "14001\n",
      "14101\n",
      "14201\n",
      "14301\n",
      "14401\n"
     ]
    }
   ],
   "source": [
    "# Let's graph the learning curves\n",
    "\n",
    "Elastic_net = ElasticNet(alpha = 0.01, l1_ratio = 0.5)\n",
    "\n",
    "#X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n",
    "train_errors, val_errors = [], []\n",
    "for m in range(1, len(X_train_trans), 100):\n",
    "    mth_X_train_trans = X_train_trans[:m]\n",
    "    Elastic_net.fit(mth_X_train_trans, y_train_trans[:m])\n",
    "    y_train_predict = Elastic_net.predict(X_train_trans[:m])\n",
    "    y_val_predict = Elastic_net.predict(X_test_trans)\n",
    "    train_errors.append(mean_squared_error(y_train_predict, y_train_trans[:m]))\n",
    "    val_errors.append(mean_squared_error(y_val_predict, y_test_trans))\n",
    "    print(m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKdxFRBJI4S4ikkAKdxGRBPr/02hqpEOgVXAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f79cffebc50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.sqrt(train_errors), \"r-+\", linewidth=2, label=\"train\")\n",
    "plt.plot(np.sqrt(val_errors), \"b-\", linewidth=3, label=\"val\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: Before you computed the final_rmse on the test data, what was your expected value for this quantity? Does your best model have high variance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### YOUR ANSWER HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "My initial expectation in regards to the final_rmse is that it should have been lower than the rmse on the training data and that the Elastic Net would fit the housing test data well. It seems that our final Elastic Net model fits the housing data well. Why ? - rmse on the training data is 0.5693085940347592 and the rmse on the testing data is 0.5714043869205295."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Our final model, Elastic Net, seems to have have a minimal amout of variance as can be seen from the graph above. Additionally, MRSE for train set and test set are low. Next, the difrerence between RMSE for train set and test set is low eventhough RMSE for test set is miniscually higher. Therefore, the variance is low.\n",
    "\n",
    "Now, let's take a look at plt.scatter(x=y_test_trans, y=y_test_estimation_trans) once again. On the far right, at x ~= 2.5, we can a see a straight vertical line corresponding to the y=y_test_estimation_trans. Therefore, due to that straight line, we might have a higher than necessary variance. Thus, to decrease the variance, we would need to delete some of the values of y=y_test_estimation_trans corresponding to the vertical line and run the model again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now, let's drop some values from x=y_test_trans and y=y_test_estimation_trans\n",
    "\n",
    "x = y_test_trans\n",
    "y = y_te_estimation\n",
    "\n",
    "master_array_1 = np.append(x.reshape(-1,1), y.reshape(-1,1), axis = 1).T\n",
    "master_array = np.round_(master_array_1, decimals = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.375642, -1.392057,  2.532087, ...,  0.099149, -0.756178,\n",
       "         0.024848],\n",
       "       [-1.231869, -0.844502,  0.461159, ...,  0.49947 , -0.791459,\n",
       "         0.062471]])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master_dframe = pd.DataFrame(master_array).T.sort_values(by = [0], ascending = True)\n",
    "master_dframe.columns = ['x', 'y']\n",
    "#master_dframe\n",
    "rows_to_drop = master_dframe.index[master_dframe['x'] == 2.532087].tolist()\n",
    "# Dropping the rows\n",
    "new_master_dframe = master_dframe.drop(rows_to_drop)\n",
    "new_master_array = np.array(new_master_dframe.T)\n",
    "x_new = new_master_array[0]\n",
    "y_new = new_master_array[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDBp2QggpGDTshBBSMP4/WSnftu4+4HcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f79cfc5bcc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x=x_new, y=y_new)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5091321246868359\n"
     ]
    }
   ],
   "source": [
    "final_mse = mean_squared_error(x_new, y_new)\n",
    "final_rmse = np.sqrt(final_mse)\n",
    "print(final_rmse) # 0.5091321246868359"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WOW! The rmse drops even further. The model seems to fit the data even better. Isn't this great?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#[Optional]\n",
    "Why does the matrix X appears transponsed in the normal equation in the linear regression? Equation 4.4. Start from equation 4.3\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let's rewrite the MSE cost function for a Linear Regression model in a matrix notation:\n",
    "\n",
    "$$J(\\theta) = \\frac{1}{2m} (X \\theta  - y)^T(X \\theta - y)$$\n",
    "\n",
    "$$J(\\theta) = \\frac{1}{2m} ((X \\theta)^T - y^T)(X \\theta - y)$$\n",
    "$$J(\\theta) = \\frac{1}{2m} ((X \\theta)^T X \\theta - (X \\theta)^T y - y^T (X \\theta) + y^Ty)$$\n",
    "$$J(\\theta) = \\frac{1}{2m} (\\theta^T X^T X \\theta - 2(X \\theta)^T y + y^Ty)$$\n",
    "$$\\frac{\\partial J}{\\partial \\theta} = 2 X^T X \\theta  - 2X^T y = 0$$\n",
    "$$ X^T X \\theta = X^T y$$\n",
    "$$ \\hat\\theta = (X^T X)^{-1}X^Ty$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#[Optional]\n",
    "Do all Gradient Descent algorithms lead to the same model provided you let them run long enough?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "If the optimization problem is convex (such as Linear Regression or Logistic Regression), and assuming the learning rate is not too high, then all Gradient Descent algorithms will approachthe global optimum and end up producing fairly similar models. Howere, unless you gradually reduce the learning rate, Stochastic GD and Mini-Batch GD will never truly converge; instead, they will keep jumping back and forth around the global optimum. This means that even if you let them run for a very long time, these Gradient Descent algorithms will produce slightly different models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#[Optional]\n",
    "Is it a good idea to stop Mini-batch Gradient Descent immediately when the validation error goes up?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Due to their random nature, neither Stochastic Gradient Descent nor Mini-Batch Gradient Descent is guaranteed to make progress at every single iteration. So, if you immediately stop training when the validation error goes up, you may stop much too early, before the optimum is reached. A better option is to save the model at regular intervals, and when it has not improved for a long time (meaning it will probably never beat the record), you can revert to the best saved model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#[Optional]\n",
    "Suppose you are using Ridge Regression and you notice that the training error and the validation error are almost equal and fairly high. Would you say that the model suffers from high bias or high variance? Should you increase the regularization hyperparameter α or reduce it?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "If both the training error and the validation error are almost equal and fairly high, the model is likely underfitting the training set, which means it has a high bias. We should try reducing the regularization hyperparameter $\\alpha$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#[Optional]\n",
    "Why does the matrix X appears transponsed in the normal equation in the linear regression? Equation 4.4. Start from equation 4.3\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let's rewrite the MSE cost function for a Linear Regression model in a matrix notation:\n",
    "\n",
    "$$J(\\theta) = \\frac{1}{2m} (X \\theta  - y)^T(X \\theta - y)$$\n",
    "\n",
    "$$J(\\theta) = \\frac{1}{2m} ((X \\theta)^T - y^T)(X \\theta - y)$$\n",
    "$$J(\\theta) = \\frac{1}{2m} ((X \\theta)^T X \\theta - (X \\theta)^T y - y^T (X \\theta) + y^Ty)$$\n",
    "$$J(\\theta) = \\frac{1}{2m} (\\theta^T X^T X \\theta - 2(X \\theta)^T y + y^Ty)$$\n",
    "$$\\frac{\\partial J}{\\partial \\theta} = 2 X^T X \\theta  - 2X^T y = 0$$\n",
    "$$ X^T X \\theta = X^T y$$\n",
    "$$ \\hat\\theta = (X^T X)^{-1}X^Ty$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
